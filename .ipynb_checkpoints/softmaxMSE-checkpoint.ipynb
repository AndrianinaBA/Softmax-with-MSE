{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62736727-4e95-40a7-86b4-861ca75f9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bcc9d634-9bbb-427f-96f1-8f12b133bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def One_hot_encoder(num_classes):\n",
    "    OHE = {i : np.array([1 if k == i else 0 for k in range(num_classes)]) for i in range(num_classes)}\n",
    "    return OHE\n",
    "\n",
    "def softmax(t):\n",
    "    exp_t = np.exp(t - np.max(t))\n",
    "    return exp_t / (np.sum(exp_t))\n",
    "\n",
    "class SoftmaxMSE:\n",
    "    def __init__(self,num_classes,lr=0.01,num_epochs=2):\n",
    "        self.lr = lr\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_classes = num_classes\n",
    "        self.weight = None\n",
    "        self.bias = None\n",
    "        self.encoder = One_hot_encoder(self.num_classes)\n",
    "\n",
    "    def forward(self,X):\n",
    "        tmp = self.weight @ X + self.bias\n",
    "        return softmax(tmp)\n",
    "\n",
    "    def parametrize(self,X,y):\n",
    "        self.n_sample, self.n_feature = X.shape[0], X.shape[1]\n",
    "        self.weight = np.random.randn(self.num_classes,self.n_feature)\n",
    "        self.bias = np.random.randn(self.num_classes)\n",
    "\n",
    "    def MSE(self,logits,y):\n",
    "        return 0.5 * np.sum(np.square(logits - self.encoder[y]))\n",
    "\n",
    "    def MSE_prime(self,logits,k,y):\n",
    "        d_k =  np.array([-logits[k] *(logits[i] - np.where(y==i,1,0)) if i != k else -logits[k] *(logits[i] - 1)*(logits[i]- np.where(y==i,1,0))  for i in range(self.num_classes)]) \n",
    "        #d_k -=   self.encoder[y]\n",
    "        #print(d_k)\n",
    "        tmp = np.sum(d_k)\n",
    "        #print(tmp,y)\n",
    "        return tmp\n",
    "        \n",
    "    def train(self,X,y):\n",
    "        \n",
    "        for _ in range(self.num_epochs):\n",
    "            for x, y_ in zip(X,y):\n",
    "                logits = self.forward(x)\n",
    "                #print(logits)\n",
    "                #mse_prime = np.sum(logits - self.encoder[y_])\n",
    "                \n",
    "                for k in range(self.num_classes) : \n",
    "                    t = self.MSE_prime(logits,k,y_)\n",
    "                    #print(t)\n",
    "                    self.weight[k] -= self.lr * t * x\n",
    "                    self.bias[k]-= self.lr * t\n",
    "        \n",
    "\n",
    "    def predict(self,x):\n",
    "        res = self.forward(x)\n",
    "        return np.argmax(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "468f0962-2179-4ede-8655-a91c6fba6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7314ea7d-f251-4ca2-b26a-e92f04cbbb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2dc9a5d9-8f70-4c3e-aee3-6bc72dbac471",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X ,y , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "035e6d1b-2aad-4a5d-8f91-2b09899947a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SoftmaxMSE(num_classes=3, num_epochs=100, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5d5dbe53-c7f6-42b7-8760-27d758857516",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.parametrize(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "522375e3-ce0c-4a2c-89b3-779619bafbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.train(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "20981709-3728-40bb-b350-7e9f15b6f3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.84024049, 11.74757421,  4.64236633,  0.5224238 ],\n",
       "       [15.96501366,  6.64462995, 13.25068168,  3.05133067],\n",
       "       [14.65791019,  4.87154416, 15.52859934,  6.04648558]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f612521f-f679-4ea6-b5c8-65d0897324e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.2900666 ,  2.40694898, -0.01467799])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5b2e2656-5596-45db-87e6-af0b613a2a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(37)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =  []\n",
    "for x in X_test:\n",
    "    y_pred.append(clf.predict(x))\n",
    "\n",
    "np.sum(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb70d6-99bc-4c83-ace0-26be4630d404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
